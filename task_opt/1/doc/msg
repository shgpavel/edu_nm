Инструкция по методам оптимизации
1. В методе золотого сечения посмотрите внимательно, возможно у вас на последней
итерации зазря происходит еще одно вычисление функции. Решается это следующим образом - вместо
вычисления новой правой/левой точки поставьте логическую переменную, допустим count_left, которая true
если нужно вычислять левую и false если нужно вычислять правую. Затем уже после условия, внутри которого
вы пересчитываете границы и присваиваете значение логической переменной, но до выхода из while, намутите
еще одну проверку на достижение погрешности. Если нужная погрешность еще не достигнута, тут-то и вычисляйте
функцию в нужном месте (в зависимости от значения вашей логической переменной). Или возможно все можно сделать
как-то легче, работая через do-while, но я сделал именно так.

3. Помимо итога, нужно выводить еще и результаты каждой итерации. Для метода дихотомии и золотого сечения
у нас есть отрезок [a,b], а внутри него расположены точки c и d (c<d); и выводить нужно следующее:

номер_итерации; x_a; x_b; x_c; x_d; f(x_c); f(x_d) - f(x_c)
Все, разумеется, в 16-ричном формате.

Для направленного поиска вывод немного другой:

на этапе поиска триады:
номер_итерации, x_cur, x_next, f(x_cur), f(x_next), h

На этапе уточнения триады:
номер_итерации, x_left, x_center, x_right, f(x_left), f(x_center), f(x_right), h

где h - текущий шаг.

4. Методы. Метод направленного поиска михеев дал сам, а в интернете я его не нашел, так что похоже это локальная
фича нашего факультета. Если нужно, могу скинуть конспекты по этому методу, я его неплохо записал.
Методы дихотомии и золотого сечения написаны в учебнике (могу скинуть учебник), но там мне кажется золотое
сечение описано неверно, а верно нам объяснили на лекции вчера, опять же могу скинуть конспекты.
